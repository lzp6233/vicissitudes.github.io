# 简明报告：大语言模型模型编辑技术 (2024-2025)

## 1. 核心问题：模型不懂“变通”
大语言模型（LLM）很强大，但有一个致命弱点：**一旦训练完成，它的知识就固定了**。
如果现实世界变了（比如英国首相换人了），模型还在说旧信息。
- **重训（Retraining）**：太贵，太慢。
- **微调（Fine-tuning）**：容易让模型“学了新知识，忘了旧本领”（灾难性遗忘）。

**模型编辑（Model Editing）** 就是为了解决这个问题：**精准修改特定知识，不影响其他能力。**

---

## 2. 三种主要方法
1. **外挂知识（RAG）**：不改模型，只在提问时把新知识告诉它。简单但治标不治本。
2. **合并知识**：用微调把新知识“喂”进去。
3. **直接手术（内在编辑）**：直接修改模型神经元的权重。这是目前最前沿的技术。

---

## 3. 最新技术突破 (2024-2025)

### 3.1 更精准的手术刀 (Locate-and-Edit)
- **EMMET**：把以前的单条修改（ROME）和批量修改（MEMIT）统一起来了，效率极高，一次能改上万条知识。
- **PMET**：发现知识不仅藏在“记忆区”（FFN），也藏在“注意力区”（Attention）。两边一起改，效果更好。
- **AlphaEdit (ICLR杰出论文)**：用数学方法（零空间投影）保证**修改新知识时，绝对不碰旧知识的地盘**。这是目前的理论巅峰。

### 3.2 给模型装“外脑” (架构解耦)
直接改参数改多了，模型容易崩。新趋势是**不改原模型，只加“补丁”**。
- **WISE**：给模型加一个“侧记忆”区。新知识写在侧记忆里，旧知识在主记忆里。
- **MELO**：像打补丁一样，有新知识就挂载一个小模块（LoRA），用的时候才激活。

### 3.3 机器遗忘 (Machine Unlearning)
除了让模型“记住”，有时也需要它“忘记”（比如隐私数据、有害信息）。
- **SimNPO**：不需要旧模型做对比，直接告诉模型“别说这句话”。
- **RMU**：搞乱模型的“思路”，让它在遇到敏感词时胡言乱语，从而无法输出有害信息。

---

## 4. 风险与挑战
- **编辑攻击**：坏人可以用这些工具给模型植入错误知识或偏见，而且很难被发现。
- **蝴蝶效应**：改了一个知识点（如：A是B的父亲），模型往往推导不出相关的逻辑（如：B是A的儿子）。
- **语言隔阂**：在英文语境下改了知识，中文语境下可能没生效。

## 5. 总结
现在的技术已经可以比较安全地修改模型知识了。
- 想要**精准**：用 AlphaEdit。
- 想要**长期稳定**：用 WISE 或 MELO（加外脑）。
- 想要**安全**：用机器遗忘技术。

未来的目标是：让模型像人一样，既能随时学习新知，又能灵活运用逻辑，还知道什么该忘。
