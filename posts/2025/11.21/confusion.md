# 🤖 机器学习评估指标：混淆矩阵、ROC 曲线与 AUC



在机器学习中，我们训练模型来对事物进行分类（比如判断一封邮件是不是垃圾邮件）。评估一个分类模型的好坏，不能只看它“猜对”了多少次，还需要更细致的指标。

## 1. 混淆矩阵 (Confusion Matrix)

混淆矩阵是评估分类模型性能的基础工具。它是一个表格，用来展示模型在所有分类结果上的表现，尤其是在**二分类问题**中（比如：是/否，真/假，阳性/阴性）。

|                            | **预测为 阳性 (Positive)** | **预测为 阴性 (Negative)** |
| -------------------------- | -------------------------- | -------------------------- |
| **实际为 阳性 (Positive)** | **真正例 (TP)**            | **假反例 (FN)**            |
| **实际为 阴性 (Negative)** | **假正例 (FP)**            | **真反例 (TN)**            |

### 💡 核心概念解读 (以疾病检测为例)

- **真正例 (TP - True Positive):** **实际有病**，模型**预测有病**。 (恭喜！猜对了)
- **真反例 (TN - True Negative):** **实际没病**，模型**预测没病**。 (很好！猜对了)
- **假正例 (FP - False Positive):** **实际没病**，模型**预测有病**。 (误报！**I 类错误**)
- **假反例 (FN - False Negative):** **实际有病**，模型**预测没病**。 (漏报！**II 类错误**)

### 关键衍生指标

| **指标名称**                         | **计算公式**                        | **通俗理解**                                 |
| ------------------------------------ | ----------------------------------- | -------------------------------------------- |
| **准确率 (Accuracy)**                | $$(TP + TN) / (TP + TN + FP + FN)$$ | 所有预测正确的比例。                         |
| **召回率 (Recall) / 真正例率 (TPR)** | $$TP / (TP + FN)$$                  | 实际为阳性的样本中，被正确预测的比例。       |
| **精确率 (Precision)**               | $$TP / (TP + FP)$$                  | 预测为阳性的样本中，有多少是真的阳性。       |
| **假正例率 (FPR)**                   | $$FP / (FP + TN)$$                  | 实际为阴性的样本中，被错误预测为阳性的比例。 |



## 2. ROC 曲线 (Receiver Operating Characteristic Curve)

**ROC 曲线**是根据模型的**预测得分**（或概率）来画的一条曲线。它展现了在不同的**分类阈值**下，模型的 **真正例率 (TPR)** 和 **假正例率 (FPR)** 之间的权衡关系。



### 🔑 ROC 曲线的坐标轴



- **X 轴：假正例率 (FPR)**

  $$(FP / (FP + TN))$$

- **Y 轴：真正例率 (TPR) / 召回率 (Recall)**

  $$(TP / (TP + FN))$$



### 📈 ROC 曲线的意义



- **理想情况：** 曲线应尽可能靠近图的**左上角 (0, 1)**。这意味着：
  - **FPR 接近 0：** 误报很少。
  - **TPR 接近 1：** 漏报很少，召回率高。
- **对角线 (Y=X)：** 这代表一个随机猜测的模型，即模型性能毫无价值。
- **曲线越靠近左上角，模型性能越好。**

------

## 3. AUC (Area Under the Curve)

**AUC** 就是 **ROC 曲线下方的面积 (Area Under the Curve)**。

### 📊 AUC 的计算和意义

- **取值范围：** AUC 的取值在 0.5 到 1.0 之间。
- **值越大越好：**
  - **AUC = 1.0：** 完美分类器。
  - **AUC = 0.5：** 相当于随机猜测。
- **通俗理解：** AUC 可以理解为：**随机抽取一个正样本**和**随机抽取一个负样本**，模型将**正样本的预测概率**高于**负样本的预测概率**的概率。

> **一个 AUC 值为 0.8 的模型意味着：** 随机抽取一对正负样本，模型有 80% 的概率认为正样本比负样本更“像”正样本。

## 4. ✍️ AUC 曲线的绘制步骤

ROC 曲线的绘制是理解 AUC 的关键。模型通常输出的是一个概率值（比如：垃圾邮件的概率是 0.9）。我们需要根据这些概率值来计算 TPR 和 FPR。

### 步骤 1: 获取模型的预测概率

假设我们有 6 个样本，以及模型对它们是“阳性”的预测概率：

| **样本** | **实际标签** | **预测概率 (Score)** |
| -------- | ------------ | -------------------- |
| 1        | 阳性 (P)     | **0.9**              |
| 2        | 阳性 (P)     | **0.8**              |
| 3        | 阴性 (N)     | **0.7**              |
| 4        | 阳性 (P)     | **0.5**              |
| 5        | 阴性 (N)     | **0.4**              |
| 6        | 阴性 (N)     | **0.3**              |

### 步骤 2: 遍历所有可能的“分类阈值 (Threshold)”

在二分类中，我们需要设定一个**阈值**来判断：当预测概率大于这个阈值时，我们才把它归类为“阳性”。

> **如何选择阈值？** 最常用的方法是：将所有样本的**预测概率**都作为一个可能的阈值来计算一次 TPR 和 FPR。

我们从最高概率 $0.9$ 开始，依次将所有不同的预测概率作为阈值进行计算：

| **阈值 (T)**      | **TP** | **FP** | **TN** | **FN** | **TPR (Y 轴)** | **FPR (X 轴)** | **ROC 坐标点 (FPR, TPR)** |
| ----------------- | ------ | ------ | ------ | ------ | -------------- | -------------- | ------------------------- |
| **> 1.0 (起点)**  | 0      | 0      | 3      | 3      | 0/3 = **0**    | 0/3 = **0**    | **(0, 0)**                |
| **> 0.8 (T=0.9)** | 1      | 0      | 3      | 2      | 1/3 = **0.33** | 0/3 = **0**    | **(0, 0.33)**             |
| **> 0.7 (T=0.8)** | 2      | 0      | 3      | 1      | 2/3 = **0.67** | 0/3 = **0**    | **(0, 0.67)**             |
| **> 0.5 (T=0.7)** | 2      | 1      | 2      | 1      | 2/3 = **0.67** | 1/3 = **0.33** | **(0.33, 0.67)**          |
| **> 0.4 (T=0.5)** | 3      | 1      | 2      | 0      | 3/3 = **1**    | 1/3 = **0.33** | **(0.33, 1)**             |
| **> 0.3 (T=0.4)** | 3      | 2      | 1      | 0      | 3/3 = **1**    | 2/3 = **0.67** | **(0.67, 1)**             |
| **> 0.0 (终点)**  | 3      | 3      | 0      | 0      | 3/3 = **1**    | 3/3 = **1**    | **(1, 1)**                |

*(注：在计算 TPR 和 FPR 时，**P (实际阳性)** 总数是 3，**N (实际阴性)** 总数是 3。)*

### 步骤 3: 绘制和计算 AUC

1. 将上述计算出的所有 **(FPR, TPR)** 坐标点连接起来，就得到了 **ROC 曲线**。
   - 曲线总是从 **(0, 0)** 开始，到 **(1, 1)** 结束。
2. **AUC 的计算：** AUC 就是这条曲线下的面积。在实际应用中，由于曲线是由许多直线段连接而成，AUC 可以近似看作是所有这些直线段下方的梯形面积之和。

$$AUC = \sum_{i=1}^{m} \frac{(x_i - x_{i-1}) \cdot (y_i + y_{i-1})}{2}$$

- 其中 $x_i$ 和 $y_i$ 分别是第 $i$ 个点的 FPR 和 TPR。

## 总结

- **混淆矩阵**：基础表，提供 TP, FP, TN, FN 的数量。
- **ROC 曲线**：以 **FPR** 为 X 轴，**TPR** 为 Y 轴，通过遍历所有可能阈值画出的曲线。
- **AUC**：ROC 曲线下的面积，是衡量模型**整体分类能力**的优秀指标，不受具体阈值选择的影响。

------

