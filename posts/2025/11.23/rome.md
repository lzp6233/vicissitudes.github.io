# 秩一模型编辑（ROME）：大型语言模型中事实知识的定位与编辑深度研究报告





## 1. 执行摘要



随着大型语言模型（Large Language Models, LLMs）在自然语言处理领域的统治地位日益巩固，如何高效、精确地更新模型内部存储的事实知识已成为一个亟待解决的核心问题。传统的微调方法（Fine-Tuning）在面对特定事实更新时，往往面临计算成本高昂、灾难性遗忘（Catastrophic Forgetting）以及过拟合等挑战。在此背景下，Meng等人（2022）提出的“秩一模型编辑”（Rank-One Model Editing, ROME）技术，作为一种基于因果机制的可解释性编辑方法，引起了学术界和工业界的广泛关注。

本报告旨在对ROME技术进行详尽的深度剖析。报告首先探讨了大型语言模型中知识存储的理论基础，特别是“多层感知机（MLP）作为键值对（Key-Value）记忆网络”的假设。随后，通过详细拆解因果中介分析（Causal Mediation Analysis）和因果追踪（Causal Tracing）技术，阐明了ROME如何精确定位模型中存储特定事实的物理位置——即中层MLP模块在处理主语最后一个token时的激活状态。

核心部分深入解析了ROME的算法原理，包括主语表示的选取、目标向量的优化以及通过闭式解（Closed-form Solution）实现的秩一权重更新。报告通过对比实验数据，展示了ROME在零样本关系抽取（ZsRE）和反事实（CounterFact）数据集上相较于微调（FT）、MEND和Knowledge Editor等基线方法的显著优势，特别是在兼顾编辑有效性（Efficacy）、泛化性（Generalization）和特异性（Specificity）方面的卓越表现。

此外，本报告不回避ROME技术的局限性，深入探讨了近期研究指出的“致残性编辑”（Disabling Edits）、序列编辑下的模型崩溃问题以及与MEMIT等大规模编辑技术的演进关系。通过综合最新的研究成果，本报告为理解LLM内部机制及未来模型编辑技术的发展方向提供了全面的参考。



## 2. 引言：大型语言模型中的知识僵化与更新挑战





### 2.1 预训练模型的静态知识困境



以GPT-3、PaLM、Llama为代表的大型语言模型，通过在海量文本数据上的预训练，习得了丰富的世界知识。然而，这种知识获取方式本质上是静态的。一旦模型训练完成，其参数即被冻结，模型所掌握的信息便停留在训练截止的那一刻。

现实世界是动态变化的：政治领袖的更替、体育赛事的胜负、科学理论的更新每时每刻都在发生。例如，如果一个模型是在2020年训练的，它会坚定地认为当时的英国首相是鲍里斯·约翰逊，而在2024年这已成为过时信息。更严重的是，由于训练数据中不可避免地包含错误信息或偏见，模型可能会内化并生成有害内容 1。

对于这些庞大的模型，重新进行全量预训练（Retraining）在计算资源和时间成本上是不可接受的。因此，如何在不重新训练整个模型的情况下，像修补软件代码一样精确地“修补”模型中的特定事实错误，成为了“模型编辑”（Model Editing）领域的圣杯。



### 2.2 知识编辑的“知道”与“说出”



在模型编辑中，一个核心的区别在于让模型“说出”一个事实与真正“知道”一个事实之间的差异。Meng等人（2022）的研究敏锐地指出了这一点：通过简单的微调，我们可以轻易地强迫模型在面对“埃菲尔铁塔在哪里？”的提问时回答“罗马”。但这并不意味着模型真正修改了其内部的世界模型 1。

真正的知识编辑要求模型展现出**一致性（Consistency）\**和\**泛化性（Generalization）**。如果模型真的认为埃菲尔铁塔在罗马，那么当用户问“埃菲尔铁塔附近的食物怎么样？”时，模型应当推荐意大利面和披萨，而不是法式蜗牛；当用户用法语提问时，模型也应给出一致的答案。ROME技术的提出，正是为了解决这一深层次的知识植入问题，而非仅仅是表层的文本生成控制 1。



### 2.3 现有技术的局限性



在ROME出现之前，研究人员主要采用以下几种策略：

- **朴素微调（Naive Fine-Tuning, FT）：** 直接在包含新知识的数据上通过梯度下降更新模型参数。这种方法通常导致严重的“过拟合”，模型只能机械地记忆特定的训练样本，而无法泛化到同义转述。更糟糕的是，它容易引发“灾难性遗忘”，破坏模型原有的其他知识 2。
- **受限微调（Constrained Fine-Tuning, FT+L）：** 在微调过程中加入正则化项，限制参数偏离预训练值的幅度。这在一定程度上缓解了遗忘问题，但往往导致编辑效果不彻底，模型在新旧知识之间产生混淆 1。
- **超网络方法（Hypernetworks, 如MEND, KE）：** 训练一个额外的辅助网络（超网络）来预测模型参数的更新量。虽然这些方法在推理时效率较高，且在一定程度上改善了泛化性，但它们通常只调整模型权重的极小部分，且难以处理与其训练分布差异较大的反事实知识（Counterfactual Knowledge） 1。

ROME方法的突破在于，它不再将模型视为一个黑盒进行基于梯度的优化，而是基于对Transformer内部机制的**可解释性假设**，通过解析解直接计算出权重的更新量，从而实现对特定事实的“手术式”修改。



## 3. 理论框架：Transformer中的知识存储机制



ROME技术的有效性建立在一个关于Transformer架构的强假设之上：**多层感知机（MLP）模块是事实知识的关键存储单元**。



### 3.1 线性关联记忆（Linear Associative Memory）假设



标准的Transformer层由多头自注意力机制（Multi-Head Self-Attention, MHSA）和多层感知机（MLP）组成。传统的观点认为，注意力机制负责处理token之间的长距离依赖关系，即“上下文理解”；而MLP层则负责对每个token的表示进行逐点处理 4。

Geva等人（2021）及ROME的作者提出了一种更为具体的视角：MLP层充当了**键-值存储（Key-Value Store）**的角色。在数学上，一个全连接层可以被视为一个线性联想记忆网络。对于输入向量 $x$，MLP的第一层将其投影到“键”（Key）空间，激活特定的神经元；第二层则将这些激活映射回“值”（Value）空间，从而检索出与输入相关的信息 4。

在这种视角下，一个事实（例如“埃菲尔铁塔”->“在巴黎”）被编码为MLP权重矩阵中的一组特定的键值对映射。输入“埃菲尔铁塔”的向量表示作为查询键，触发MLP输出“在巴黎”的向量表示。



### 3.2 因果中介分析与因果追踪（Causal Tracing）



为了验证上述假设并精确定位特定事实在模型中的物理位置，ROME的研究团队引入了**因果中介分析（Causal Mediation Analysis）**方法。这一方法旨在量化模型内部中间状态（Hidden States）对最终输出预测的因果贡献 1。



#### 3.2.1 实验设计：损坏与修复



因果追踪通过三次不同的模型运行来计算特定状态的因果效应 4：

1. **清洁运行（Clean Run）：** 输入完整的事实提示 $x$（例如“Space Needle is located in”），记录模型正确预测目标 $o$（“Seattle”）时的所有内部激活状态 $h_{clean}$。
2. **损坏运行（Corrupted Run）：** 对输入提示的主语部分（“Space Needle”）添加高斯噪声。噪声的强度经过校准（通常是嵌入层标准差的3倍），足以破坏包含主语信息的特定向量，使得模型无法预测出正确答案 $o$，而只能输出一般的相关词汇或无意义内容。这创造了一个“知识缺失”的基线状态 8。
3. **修复运行（Restored Run）：** 再次输入带有噪声的提示，但在模型的前向传播过程中，强制将某个特定层 $l$ 在特定位置 $i$ 的激活状态 $h^{(l)}_i$ 替换为**清洁运行**中记录的对应状态 $h_{clean}^{(l, i)}$。



#### 3.2.2 间接效应（Indirect Effect）的量化



通过比较修复运行与损坏运行中模型输出正确答案 $o$ 的概率差异，可以计算出该状态的**间接效应（IE）**：

$$ \text{IE} = P(o \mid x_{corrupted}, \text{do}(h^{(l)}*i = h*{clean}^{(l, i)})) - P(o \mid x_{corrupted}) $$

这个指标衡量了单一状态的恢复在多大程度上能够“挽救”模型的预测。如果某个状态的IE值很高，说明该状态携带了预测所需的核心事实信息 4。



### 3.3 关键发现：中层MLP与主语末尾



对GPT-2 XL和GPT-J等模型的因果追踪揭示了两个惊人的规律，这些规律构成了ROME技术的基石：

1. **空间定位：中层MLP的决定性作用。** 实验显示，事实知识的检索主要发生在中层（例如GPT-2 XL的第15-20层）的MLP模块中。相比之下，注意力机制在事实回忆中的因果效应较小，或者主要起到将信息从MLP复制到输出端的作用 4。
2. **时间定位：主语的最后一个Token。** 最大的因果效应并不分布在主语的所有Token上，而是高度集中在主语的**最后一个Token**处（例如“The Space Needle”中的“Needle”）。这表明模型在处理到主语结束时，通过中层MLP“查表”获得了关于该实体的属性信息，并将这些信息写入到残差流中供后续计算使用 4。

基于这一发现，ROME技术将编辑的目标锁定在**处理主语最后一个Token的中层MLP权重矩阵**上。



## 4. 技术原理：秩一模型编辑（ROME）算法详解



ROME的核心思想是将模型编辑问题转化为一个带约束的最小二乘问题，并通过秩一更新（Rank-One Update）来求解。这使得我们能够精确地插入一条新的知识关联，同时最小化对模型现有知识的破坏。



### 4.1 符号定义与问题建模



设我们要编辑的目标层（即通过因果追踪选定的关键层）的MLP输出投影矩阵为 $W_0$。

我们的目标是将一条新的事实 $(s, r, o^*)$ 注入模型，以替换旧事实 $(s, r, o_c)$。

这可以分解为找到一对键向量 $k_*$ 和值向量 $v_*$，并更新权重矩阵为 $W_{new}$，使得：



$$W_{new} k_* = v_*$$



同时，为了保持模型的原有能力，我们需要 $W_{new}$ 在除了 $k_*$ 以外的所有输入上尽可能接近 $W_0$。



### 4.2 算法步骤一：选择主语的键向量 $k_*$



键向量 $k_*$ 代表了主语 $s$ 在目标层的表示。然而，主语的表示是上下文相关的。为了使编辑具有鲁棒性（Robustness），ROME不仅使用单一的提示，而是采样一组不同的前缀文本（Prefixes），计算主语最后一个Token在这些上下文中的平均激活值 11。

$$k_* = \frac{1}{N} \sum_{j=1}^{N} h(x_{prefix_j} + s)$$

这种平均化处理确保了 $k_*$ 捕获的是主语的核心语义特征，而非特定上下文的偶发特征，从而提高了编辑后的泛化能力。



### 4.3 算法步骤二：优化目标值向量 $v_*$



值向量 $v_*$ 是我们希望MLP在接收到 $k_*$ 时输出的向量。这个向量必须包含足够的信息，以驱动后续的模型层预测出新的目标词 $o^*$。

由于我们不知道后续层具体的非线性变换函数，ROME采用基于梯度的优化方法来寻找 $v_*$。

我们将 $v$ 初始化为当前的MLP输出，然后冻结模型的其余部分，定义损失函数为：

1. 最大化新目标 $o^*$ 的概率 $P(o^*)$。
2. 最小化与原始输出的KL散度（可选，用于保持局部连贯性）。

$$ v_* = \mathop{\mathrm{argmin}}*v \left[ -\log P*{model}(o^* \mid \text{do}(h=v)) + \lambda \mathcal{L}_{KL} \right] $$

通过在 $v$ 上运行若干步梯度下降（通常使用Adam优化器），我们得到一个“神奇”的向量 $v_*$，只要将它插入到残差流中，模型就会自信地输出新知识 13。



### 4.4 算法步骤三：计算秩一更新 $\Delta$



现在我们有了键 $k_*$ 和目标值 $v_*$，问题转化为求解 $W_{new}$。

根据最小二乘原理，若要修改线性映射 $W$ 对特定方向 $k_*$ 的响应，同时保留对其他方向（由协方差矩阵 $C = \mathbb{E}$ 定义）的响应不变，最优解形式为 $W_{new} = W_0 + \Delta$，其中 $\Delta$ 是一个秩一矩阵 6。

更新公式推导如下：



$$\Delta = \frac{(v_* - W_0 k_*) (C^{-1} k_*)^T}{k_*^T C^{-1} k_*}$$

这里：

- $(v_* - W_0 k_*)$ 是**残差项**，表示当前输出与目标输出的差距。
- $k_*^T C^{-1}$ 是**投影项**，利用预先计算的键协方差矩阵的逆 $C^{-1}$ 对键进行“白化”处理。这一步至关重要，因为它考虑了特征空间的相关性，确保更新仅在与 $k_*$ 相关的方向上生效，而与其正交的方向（即其他知识）不受影响。

最终的权重更新规则为：



$$W_{new} = W_0 + \Lambda (v_* - W_0 k_*) k_*^T C^{-1}$$



（注：$\Lambda$ 为归一化系数 $(k_*^T C^{-1} k_*)^{-1}$）

这一闭式解不仅计算高效，而且具有明确的几何意义：它在特征空间中沿着特定方向扭曲了流形，以嵌入新的记忆点 16。



## 5. 实验评估：数据集与指标



为了全面验证ROME的性能，研究者主要使用了两个数据集，并定义了三个核心指标。



### 5.1 数据集对比：ZsRE 与 CounterFact



- **ZsRE (Zero-Shot Relation Extraction):** 基于问答的数据集。任务是改变模型对特定问题的回答。例如，“谁是Villa Kampen的建筑师？”。
  - *局限性：* ZsRE被认为相对简单，因为模型对某些生僻事实可能没有强烈的先验信念。此外，ZsRE的评估往往局限于问答形式，难以测试模型在自由文本生成中的表现 17。
- **CounterFact:** 由Meng等人专门为ROME开发的高难度数据集。它包含超过20,000条反事实编辑任务（例如“让模型认为埃菲尔铁塔在罗马”）。
  - *优势：* CounterFact旨在对抗模型在预训练中形成的强关联（Prior Knowledge）。它不仅测试模型是否能“记住”新事实，还通过改写提示（Paraphrases）和邻域主语（Neighborhood Subjects）来严格测试泛化性和特异性 4。



### 5.2 评估指标体系



为了区分“知道”与“说出”，评估必须多维度进行 4：

1. **有效性 (Efficacy, ES):** 编辑后，模型在特定提示下输出目标 $o^*$ 的成功率。
   - *公式：* $P(o^* \mid x_{edit}) > P(o_c \mid x_{edit})$
2. **泛化性 (Generalization/Paraphrase, PS):** 模型在语义相同但句法不同的提示下，能否依然输出目标 $o^*$。这是衡量模型是否真正理解了知识的关键。
3. **特异性 (Specificity/Locality, NS):** 模型对无关事实的判断是否受影响。例如，将“埃菲尔铁塔”移至“罗马”后，“卢浮宫”的位置应当依然是“巴黎”。如果模型错误地认为卢浮宫也在罗马，则发生了**知识泄露（Bleedover）**。



## 6. 优势分析：ROME 与基线方法的比较



实验数据表明，ROME在综合性能上显著优于传统的微调和早期的模型编辑方法。



### 6.1 综合性能对比表（基于GPT-2 XL与GPT-J）



| **方法**             | **有效性 (Efficacy)** | **泛化性 (Generalization)** | **特异性 (Specificity)** | **优势/劣势分析**                                            |
| -------------------- | --------------------- | --------------------------- | ------------------------ | ------------------------------------------------------------ |
| **Fine-Tuning (FT)** | 高 (>99%)             | 中等                        | **极低**                 | 严重的过拟合，容易破坏邻近知识（如将所有塔都移到罗马）3。    |
| **FT + L1约束**      | 中等                  | 差                          | 高                       | 过于保守，导致新知识难以有效注入，往往导致模型输出混乱 4。   |
| **MEND (超网络)**    | 高                    | 差                          | **高**                   | 作为一个训练好的“补丁生成器”，MEND在特异性上表现出色，但在面对反事实这种强冲突任务时，泛化能力不足，且需要额外的训练阶段 5。 |
| **ROME**             | **高 (>99%)**         | **高**                      | **高**                   | **优势总结：** ROME是唯一在三个指标上都保持高水平的方法。它通过直接操作存储机制，实现了真正的“知识植入”而非表面记忆 4。 |





### 6.2 ROME的核心优势



1. **精准性与可解释性：** ROME不依赖黑盒优化，而是基于对模型内部机制（MLP作为键值存储）的理解。这使得编辑过程透明、可控，且具有明确的理论保障 4。
2. **零样本泛化：** 得益于 $k_*$ 的上下文平均处理和 $v_*$ 的优化，ROME编辑后的模型能够处理未见过的句式。例如，编辑“梅西通过..运动”为“篮球”后，模型能在“梅西不仅是足球巨星，他也是著名的...球员”中填入“篮球”，展现出对概念的深层绑定 4。
3. **无需额外训练：** 与MEND或KE不同，ROME不需要预先训练一个庞大的超网络。它只需要对当前样本进行一次因果追踪和一次矩阵更新计算，计算资源消耗主要在推理端，而非训练端。
4. **维持不相关知识的稳定性：** 通过引入协方差矩阵 $C^{-1}$，ROME显式地要求更新向量与现有的知识空间正交。实验证明，这极大地减少了对模型其他能力的干扰 19。



## 7. 局限性与挑战：ROME的“陨落”



尽管ROME在单次编辑任务上取得了巨大成功，但随着研究的深入，其在复杂场景下的局限性逐渐暴露。近期的研究（2023-2024）揭示了ROME在扩展性上的严重缺陷。



### 7.1 序列编辑的崩溃（The Sequential Editing Problem）



ROME最初是为单次编辑设计的。当研究者尝试对同一个模型连续进行多次编辑（例如连续修正100个事实）时，模型性能出现了显著下降。

- **渐进性遗忘 (Gradual Forgetting):** 每一次秩一更新都会引入微小的噪声。由于实际的键向量之间并非完全正交，这些噪声会累积，导致早期编辑的事实逐渐被覆盖或失效 20。
- **灾难性崩溃 (Catastrophic Collapse):** 更为严重的是，Gupta等人（2024）发现，在进行约10-50次编辑后（取决于模型大小），模型会突然丧失语言能力，生成的文本变成乱码，困惑度（Perplexity）指数级上升。这表明频繁的秩一扰动破坏了权重矩阵的谱结构 20。



### 7.2 “致残性编辑” (Disabling Edits)



Yang等人（2024）在EMNLP发表的论文《The Fall of ROME》中指出，甚至某些**单次编辑**也能直接摧毁模型。

- **原因分析：** 这一现象主要源于算法实现中的不一致性。ROME在计算 $k_*$ 时使用了带前缀的平均向量，但在更新公式的分母项 $k_*^T C^{-1} k_*$ 中，如果主语（特别是作为句子开头的第一个Token）的分布与预计算的协方差 $C$ 差异巨大，会导致分母极小，进而使得更新量 $\Delta$ 的模长爆炸（Magnitude Explosion）。
- **后果：** 一个巨大的 $\Delta$ 会彻底改变MLP层的权重分布，导致模型对任何输入都产生异常激活。
- **修复方案 (r-ROME):** 通过统一键向量的计算方式（在所有步骤中均使用相同类型的前缀处理），可以消除这种数值不稳定性 21。



### 7.3 知识泄露的深层问题



虽然ROME在标准特异性指标上表现良好，但使用更敏感的指标（如邻域KL散度）进行的测试表明，ROME依然存在显著的“知识泄露”现象。例如，修改关于某个国家的事实可能会微妙地改变模型对该国其他城市的描述风格。这暗示了知识在LLM中并非完全模块化，而是存在全息式的纠缠 20。



## 8. 演进：从 ROME 到 MEMIT 与 EMMET



针对ROME在扩展性上的不足，Meng等人（2023）及后续研究者提出了改进方案，标志着模型编辑技术进入了“批量编辑”（Mass-Editing）时代。



### 8.1 MEMIT：多层分布式编辑



MEMIT（Mass-Editing Memory in a Transformer）是ROME的直接继承者。它针对ROME“单层过载”的问题提出了解决方案 13。

- **多层分摊：** MEMIT不再将所有新知识强塞进某一层MLP，而是将更新量分散到一系列层（例如GPT-J的第3-8层）。
- **最小二乘松弛：** MEMIT将ROME的严格等式约束 $W k = v$ 放宽为最小二乘目标，允许同时处理成千上万个编辑请求（Batched Edits）。
- **效果：** MEMIT成功在GPT-J上实现了超过10,000次事实更新，且保持了较高的模型稳定性，显著延缓了灾难性遗忘的发生 26。



### 8.2 EMMET：理论统一



Gupta等人（2024）提出的EMMET算法进一步在理论上统一了ROME和MEMIT。他们证明了ROME实际上是MEMIT在单层、单次编辑下的特例。EMMET引入了等式约束的批量编辑形式，揭示了模型编辑本质上是在权衡“记忆新知识”与“保留旧参数”之间的优化路径 25。



## 9. 结论与展望



ROME技术的提出是大型语言模型可解释性研究的一个里程碑。它不仅仅是一种工程上的修补工具，更是对“神经网络如何记忆”这一根本科学问题的有力回应。通过将MLP层建模为线性关联记忆，并利用因果分析定位知识坐标，ROME证明了我们有能力打开黑盒，对模型的认知结构进行精细的外科手术。

尽管原始的ROME算法在序列编辑和极端情况稳定性上存在缺陷，但它确立的“定位-计算-更新”范式（Locate-then-Edit Paradigm）已成为该领域的标准。随着r-ROME对稳定性的修复以及MEMIT对规模化的扩展，基于梯度的权重直接编辑技术正变得日益成熟。

未来，随着模型规模迈向万亿参数，基于ROME思想的编辑技术将在以下方面发挥关键作用：

1. **AI安全与对齐：** 快速清除模型中的危险知识或植入安全护栏，而无需昂贵的重训练。
2. **实时知识更新：** 使LLM能够跟上世界的变化，成为真正的实时智能系统。
3. **神经科学启示：** 这种人工神经网络的记忆机制研究，或许能反向为理解生物大脑的记忆形成提供计算视角的启示。

综上所述，ROME不仅是一项技术，更是一把钥匙，开启了通往可解释、可控制、可进化的人工智能系统的大门。

------



## 附录：关键数学公式汇总



为了保持报告的完整性，以下列出ROME算法的核心推导公式 6：

1. 键向量计算（Key Selection）：

   

   $$k_* = \text{Mean}_{x \in \mathcal{X}} [ h(x + s) ]$$

2. 值向量优化（Value Optimization）：

   $$ v_* = \mathop{\mathrm{argmin}}{z} \left( -\log P(o^* \mid z) + \lambda D{KL}(P(\cdot \mid z) || P(\cdot \mid h_{orig})) \right) $$

3. 权重更新（Weight Update）：



$$W_{new} = W_0 + \frac{v_* - W_0 k_*}{k_*^T C^{-1} k_*} k_*^T C^{-1}$$

这些公式构成了“秩一模型编辑”的数学骨架，支撑起整个技术的有效性。



---

# 详细推导

## 1. 引言：模型编辑的背景与挑战

### 1.3 本报告的研究目标



本报告不涉及“定位”阶段的详细因果分析，而是聚焦于“编辑”阶段的数学核心。即：在已知要修改的目标层和目标事实的情况下，**如何通过严格的数学推导，得到权重矩阵 $W$ 的具体更新公式？**

我们将详细剖析以下三个核心步骤：

1. **步骤一：选择键向量 $k^\*$ (Key Selection)** —— 如何在数学上定义“这个事实的主语”？
2. **步骤二：优化值向量 $v^\*$ (Value Optimization)** —— 如何计算出“模型应当输出的新表示”？
3. **步骤三：插入事实 (Fact Insertion)** —— 如何利用拉格朗日乘数法推导出权重更新 $\Delta W$？



## 2. 理论基础：Transformer MLP 作为线性联想记忆



在深入推导之前，必须建立 ROME 所依赖的数学模型架构。



### 2.1 Transformer MLP 的结构



Transformer 的每一层主要由两个子层组成：多头自注意力机制（Multi-Head Self-Attention, MHSA）和前馈神经网络（Feed-Forward Network, MLP）。ROME 的研究重点在于 MLP 层。

一个标准的 MLP 模块包含两个线性变换和一个非线性激活函数。设 MLP 的输入为 $x$（来自注意力层的输出和残差连接），其计算过程如下：

$$\text{MLP}(x) = W_{proj} \cdot \sigma(W_{fc} \cdot x)$$

其中：

- $x \in \mathbb{R}^d$ 是模型的隐状态向量（hidden state），$d$ 为模型维度。
- $W_{fc} \in \mathbb{R}^{h \times d}$ 是第一层权重矩阵（Fully Connected），通常将维度扩展到 $h$（例如 $h=4d$）。
- $\sigma(\cdot)$ 是非线性激活函数（如 GELU 或 ReLU）。
- $W_{proj} \in \mathbb{R}^{d \times h}$ 是第二层权重矩阵（Projection），将向量映射回模型维度 $d$。



### 2.2 联想记忆假设 (Associative Memory Hypothesis)



Meng 等人（2022）提出的关键假设是：**MLP 模块充当了一个线性联想记忆（Linear Associative Memory, LAM）** 3。

在这个视角下，MLP 的第二层 $W_{proj}$ 可以被视为一个存储器，它存储了一组键值对 $(k, v)$：

- **键 (Key) $k$：** 是 MLP 中间层的激活值，即 $k = \sigma(W_{fc} x)$。这代表了输入主语（如“埃菲尔铁塔”）在某种高维空间中的特征表示。
- **值 (Value) $v$：** 是 MLP 的输出，即 $v = W_{proj} k$。这代表了模型关于该主语回忆起的事实属性（如“位于巴黎”）。
- **存储机制：** 权重矩阵 $W_{proj}$（以下简写为 $W$）通过线性变换 $Wk \approx v$ 来关联键和值。

如果模型已经记住了 $N$ 个事实，对应的键为 $K_0 = [k_1 | k_2 | \dots | k_N]$，值为 $V_0 = [v_1 | v_2 | \dots | v_N]$，那么矩阵 $W$ 实际上是以下最小二乘问题的解：

$$W \approx V_0 K_0^+$$

其中 $K_0^+$ 是 $K_0$ 的伪逆。这构成了 ROME 推导的数学起点：我们需要修改这个矩阵 $W$，使其在保持旧记忆（$K_0, V_0$）的同时，强制记住一个新的键值对 $(k^*, v^*)$。



### 2.3 符号定义表



为了清晰展示推导过程，我们定义以下数学符号：

| **符号**   | **维度**     | **定义与物理含义**                                           |
| ---------- | ------------ | ------------------------------------------------------------ |
| $W_0$      | $d \times h$ | 原始模型的 MLP 第二层权重矩阵（待编辑对象）。                |
| $\hat{W}$  | $d \times h$ | 编辑后的权重矩阵。                                           |
| $\Delta W$ | $d \times h$ | 参数更新量，即 $\hat{W} - W_0$。                             |
| $x$        | $d \times 1$ | 模型的输入隐状态向量。                                       |
| $k^*$      | $h \times 1$ | **目标键向量**，代表被编辑事实的主语（Subject）。            |
| $v^*$      | $d \times 1$ | **目标值向量**，代表希望模型输出的新属性（Target Property）。 |
| $K_0$      | $h \times N$ | 预训练过程中所有样本生成的键向量集合（假设）。               |
| $V_0$      | $d \times N$ | 预训练过程中对应的目标值向量集合。                           |
| $C$        | $h \times h$ | **协方差矩阵** $C = K_0 K_0^T$，代表预训练键向量的统计分布。 |
| $\lambda$  | $d \times 1$ | 拉格朗日乘数向量。                                           |

------



## 3. 步骤一推导：键向量 $k^*$ 的计算 (Subject Key Selection)



在 ROME 中，第一步是确定我们要编辑“什么”。由于神经网络内部不存在“埃菲尔铁塔”这样的显式符号，我们需要找到代表该主语的神经激活模式。



### 3.1 语境依赖性与平均策略



在 Transformer 中，同一个词（如 "Tower"）在不同句子中的表示是不同的（上下文相关）。为了让编辑具有**鲁棒性（Robustness）**，即无论用户如何提问（“Eiffel Tower is...”, “The height of the Eiffel Tower is...”），模型都能识别出主语，ROME 采用了一种平均策略。



### 3.2 数学表达



设 $s$ 为主语（Subject）的 token 序列。我们随机采样一组包含 $s$ 的文本前缀 $\{x_1, x_2, \dots, x_M\}$。这些前缀的作用是模拟主语可能出现的多种语境。

对于每一个输入文本 $x_j$，我们将其输入模型，并在目标层 $l^*$ 的 MLP 内部截取主语最后一个 token 处的激活值。

具体计算公式如下：



$$k^* = \frac{1}{M} \sum_{j=1}^{M} k(x_j)$$

其中 $k(x_j)$ 是单个样本生成的键向量：

$$ k(x_j) = \sigma \left( W_{fc}^{(l^)} \cdot \left( \text{LayerNorm}(a_i^{(l^-1)} + m_i^{(l^*-1)}) \right) \right) $$

这里需要特别注意细节：

1. **位置选择：** $i$ 是主语 $s$ 在句子中的最后一个 token 的索引。因果追踪（Causal Tracing）研究表明，主语的最后一个 token 汇聚了关于主语的大部分信息 1。
2. **输入源：** $k$ 是 MLP 第二层的输入，因此它是第一层 $W_{fc}$ 经过激活函数 $\sigma$ 后的输出。
3. **平均化：** 对 $M$ 个样本（通常 $M \approx 50$）取平均，得到了一个“典型”的主语表示 $k^*$。这个 $k^*$就是我们要插入新关联的“钥匙”。

------



## 4. 步骤二推导：目标值向量 $v^*$ 的优化 (Target Value Optimization)



确定了“钥匙” $k^*$ 后，下一步是确定“锁芯”应该转向的位置，即目标值 $v^*$。这个步骤最为微妙，因为我们不能直接设定 $v^*$ 为目标单词（如“Rome”）的词嵌入。MLP 的输出是在残差流（Residual Stream）中累加的，它必须与后续层的计算协同工作才能最终产生“Rome”这个预测。

因此，$v^*$ 必须通过**优化（Optimization）**来获得 3。



### 4.1 优化目标函数



我们定义一个目标向量 $z$（即潜在的 $v^*$），并构造一个损失函数 $\mathcal{L}(z)$。我们的目标是找到最优的 $z$：

$$v^* = \underset{z}{\text{argmin}} \ \mathcal{L}(z)$$

损失函数由两部分组成：



$$\mathcal{L}(z) = \mathcal{L}_{prob}(z) + \beta \mathcal{L}_{KL}(z)$$



#### 4.1.1 最大化目标概率 ($\mathcal{L}_{prob}$)



第一项要求：如果我们将 MLP 在主语位置的输出强行替换为 $z$，模型应当以高概率预测出目标宾语 $o^*$（例如 "Rome"）。

$$\mathcal{L}_{prob}(z) = - \log P_G(o^* \mid p_{fact}; \text{do}(m \leftarrow z))$$

- $p_{fact}$：事实提示语，如 "The Eiffel Tower is located in"。
- $\text{do}(m \leftarrow z)$：这是一种因果干预操作（Intervention）。意味着我们在计算图中断开原有的 MLP 输出，强制将其设置为向量 $z$。
- $P_G$：模型预测目标 token $o^*$ 的概率。

为了保证泛化性，这里同样会对多个前缀取平均。



#### 4.1.2 最小化本质漂移 ($\mathcal{L}_{KL}$) —— 保持特异性



如果仅仅最大化目标概率，优化出的 $z$ 可能会破坏主语的其他属性。例如，把埃菲尔铁塔移到罗马后，模型可能会忘记它是铁做的，或者忘记它是一座塔。

为了防止这种情况，ROME 引入了 **KL 散度（Kullback-Leibler Divergence）** 约束。我们希望在一般性描述主语的提示语（如 "The Eiffel Tower is a..."）下，模型的输出分布尽可能保持不变。

$$ \mathcal{L}*{KL}(z) = D*{KL} \left( P_G(\cdot \mid p_{essence}; \text{do}(m \leftarrow z)) \ | \ P_G(\cdot \mid p_{essence}) \right) $$

- $p_{essence}$：测试主语本质属性的提示语。
- $P_G(\cdot \mid p_{essence})$：原始模型（未修改）的输出概率分布。
- 这一项约束了 $z$ 不能包含过多与目标事实无关的干扰信息 3。



### 4.2 求解过程



这是一个关于向量 $z$ 的无约束优化问题（虽然 $z$ 作用于网络内部，但优化过程中不需要更新网络权重，只更新 $z$）。通常使用梯度下降法（Gradient Descent）求解：



$$z_{t+1} \leftarrow z_t - \eta \nabla_z \mathcal{L}(z_t)$$



经过若干步迭代后，得到的 $z$ 即为我们需要写入模型的目标值 $v^*$。

------



## 5. 步骤三推导：闭式参数更新公式 (Closed-Form Update derivation)



这是 ROME 技术的核心数学部分。现在我们有了：

1. 原始权重矩阵 $W_0$。
2. 要插入的新键值对 $(k^*, v^*)$。
3. 预训练知识的统计信息（通过 $C$ 表示）。

我们要寻找一个新的权重矩阵 $\hat{W}$，满足两个条件：

1. **硬约束（Memorization）：** 必须准确记住新事实，即 $\hat{W} k^* = v^*$。
2. **软约束（Preservation）：** 尽可能少地破坏原有知识，即对于所有旧的键 $k \in K_0$，$\hat{W} k \approx W_0 k$。



### 5.1 构建约束最小二乘问题 (Constrained Least Squares)



我们将上述目标形式化为一个带有线性等式约束的最小化问题：

$$ \begin{aligned} \text{minimize} \quad & |\hat{W} K_0 - V_0|_F^2 \ \text{subject to} \quad & \hat{W} k^* = v^* \end{aligned} $$

这里的 $\|\cdot\|_F$ 是 Frobenius 范数。

由于原始矩阵 $W_0$ 被认为是原始数据 $(K_0, V_0)$ 的最优解，我们可以合理假设 $V_0 \approx W_0 K_0$。因此，目标函数可以改写为最小化 $\hat{W}$ 对原始输出的偏离：

$$\text{minimize} \quad J(\hat{W}) = \frac{1}{2} \|\hat{W} K_0 - W_0 K_0\|_F^2$$

这种形式更加直观：我们要最小化新旧矩阵在已知键空间 $K_0$ 上的行为差异。



### 5.2 引入拉格朗日乘数 (Lagrange Multipliers)



为了解决这个带约束的优化问题，我们构造拉格朗日函数（Lagrangian） $\mathcal{L}(\hat{W}, \lambda)$。由于约束 $\hat{W} k^* - v^* = 0$ 是一个向量等式（维度为 $d$），我们需要引入一个拉格朗日乘数向量 $\lambda \in \mathbb{R}^d$。

$$ \mathcal{L}(\hat{W}, \lambda) = \frac{1}{2} |\hat{W} K_0 - W_0 K_0|_F^2 - \lambda^T (\hat{W} k^* - v^*) $$

利用迹（Trace）的性质 $\|A\|_F^2 = \text{Tr}(A A^T)$，我们可以展开第一项。为了简化推导，令 $\Delta = \hat{W} - W_0$，则目标变为最小化 $\frac{1}{2} \|\Delta K_0\|_F^2$。但为了展示完整的代数结构，我们保持 $\hat{W}$ 不变。

展开目标项：



$$\|\hat{W} K_0 - W_0 K_0\|_F^2 = \text{Tr}\left( (\hat{W} - W_0) K_0 K_0^T (\hat{W} - W_0)^T \right)$$

定义 **协方差矩阵** $C = K_0 K_0^T$ 3。这是 ROME 推导中至关重要的一步，它引入了关于预训练数据分布的信息。

此时拉格朗日函数变为：

$$ \mathcal{L} = \frac{1}{2} \text{Tr}\left( (\hat{W} - W_0) C (\hat{W} - W_0)^T \right) - \lambda^T (\hat{W} k^* - v^*) $$



### 5.3 求解梯度并令其为零



我们要针对矩阵 $\hat{W}$ 求偏导数。需要用到以下矩阵微积分恒等式：

1. $\frac{\partial}{\partial X} \text{Tr}(X C X^T) = 2XC$ （当 $C$ 对称时，这里 $C=K_0 K_0^T$ 必然对称）。
2. $\frac{\partial}{\partial X} \text{Tr}(X A) = A^T$。
3. $\lambda^T \hat{W} k^* = \text{Tr}(\lambda^T \hat{W} k^*) = \text{Tr}(\hat{W} k^* \lambda^T)$。
4. $\frac{\partial}{\partial \hat{W}} \lambda^T \hat{W} k^* = \lambda k^{*T}$ （外积形式）。

对 $\hat{W}$ 求导并设为 0：



$$\frac{\partial \mathcal{L}}{\partial \hat{W}} = (\hat{W} - W_0) C - \lambda k^{*T} = 0$$

整理得到 $\hat{W}$ 的表达式：



$$(\hat{W} - W_0) C = \lambda k^{*T}$$

$$\hat{W} - W_0 = \lambda k^{*T} C^{-1}$$

$$\hat{W} = W_0 + \lambda k^{*T} C^{-1}$$

**中间结论：** 新权重矩阵 $\hat{W}$ 等于旧权重矩阵 $W_0$ 加上一个秩一矩阵（Rank-One Matrix）。这就是 "Rank-One Model Editing" 名称的由来。这个秩一矩阵由列向量 $\lambda$ 和行向量 $k^{*T} C^{-1}$ 的外积组成。



### 5.4 求解拉格朗日乘数 $\lambda$



现在的表达式中包含未知的 $\lambda$。我们需要利用约束条件 $\hat{W} k^* = v^*$ 来解出它。

将 $\hat{W}$ 的表达式代入约束方程：



$$(W_0 + \lambda k^{*T} C^{-1}) k^* = v^*$$

展开括号：



$$W_0 k^* + \lambda (k^{*T} C^{-1} k^*) = v^*$$

注意观察括号中的项 $(k^{*T} C^{-1} k^*)$。由于 $k^*$ 是向量，$C^{-1}$ 是矩阵，这一项的计算结果是一个**标量（Scalar）**。我们将其记为常数 $\alpha$。

$$\alpha = k^{*T} C^{-1} k^*$$

方程变为：



$$W_0 k^* + \lambda \alpha = v^*$$

解出向量 $\lambda$：



$$\lambda = \frac{v^* - W_0 k^*}{\alpha} = \frac{v^* - W_0 k^*}{k^{*T} C^{-1} k^*}$$



### 5.5 最终参数更新公式 (The Final Formula)



将求解出的 $\lambda$ 代回 $\hat{W}$ 的表达式中，我们得到了 ROME 的最终参数更新公式：

$$\hat{W} = W_0 + \frac{v^* - W_0 k^*}{k^{*T} C^{-1} k^*} (C^{-1} k^*)^T$$

为了书写简洁，通常令 $\Lambda = \frac{v^* - W_0 k^*}{k^{*T} C^{-1} k^*}$ （这是一个与残差成正比的向量）。

则更新量 $\Delta W$ 为：

$$\Delta W = \hat{W} - W_0 = \Lambda (C^{-1} k^*)^T$$

或者写成更具几何意义的形式：

$$\hat{W} = W_0 + (v^* - W_0 k^*) \frac{k^{*T} C^{-1}}{k^{*T} C^{-1} k^*}$$

3

------



## 6. 深入解析：公式各部分的物理含义与作用



为了真正理解 ROME 为什么有效，我们需要“解剖”这个公式中的每一项。



### 6.1 残差项 $(v^* - W_0 k^*)$



这是**错误信号（Error Signal）**。它表示模型当前对键 $k^*$ 的输出（$W_0 k^*$）与我们期望的目标输出（$v^*$）之间的差距。更新的方向首先由这个差距决定。如果差距为 0（模型已经知道这个事实），则更新量为 0。



### 6.2 逆协方差矩阵 $C^{-1}$ —— “白化”与特异性



这是 ROME 区别于普通微调（Fine-tuning）的最关键部分。

- 在普通微调中，梯度下降的方向通常沿着 $k^*$ 方向。
- 在 ROME 中，更新方向沿着 $C^{-1} k^*$ 方向。

为什么要乘以 $C^{-1}$？

$C = K_0 K_0^T$ 编码了模型已知的所有键向量的相关性。如果 $k^*$ 与现有的某些记忆向量高度相关（即在 $C$ 的主成分方向上），$C^{-1}$ 会抑制这些方向的更新幅度。

反之，如果 $k^*$ 指向一个未被现有记忆占据的“空闲”维度（即在 $C$ 的特征值较小的方向），$C^{-1}$ 会放大这个方向。

从几何上看，$C^{-1}$ 进行了一种去相关（Decorrelation）或白化（Whitening）操作。它确保新的修改正交于模型已有的主要知识方向。这正是 ROME 能够实现极高特异性（Specificity）——只修改目标事实而不影响其他相似事实——的数学原因。



### 6.3 分母标量 $(k^{*T} C^{-1} k^*)^{-1}$



这是一个归一化因子（Normalization Factor）。它确保了更新的幅度恰好足够满足约束 $\hat{W} k^* = v^*$。

可以验证：



$$\hat{W} k^* = (W_0 + \lambda k^{*T} C^{-1}) k^* = W_0 k^* + \lambda (k^{*T} C^{-1} k^*)$$



代入 $\lambda = \frac{v^* - W_0 k^*}{k^{*T} C^{-1} k^*}$：



$$= W_0 k^* + \frac{v^* - W_0 k^*}{k^{*T} C^{-1} k^*} (k^{*T} C^{-1} k^*)$$

$$= W_0 k^* + (v^* - W_0 k^*) = v^*$$



证明完毕。这表明 ROME 是一种**一步到位（One-Shot）**的学习方法，不需要多次迭代，直接通过解析解跳到目标点。



### 6.4 数据概括表：ROME 关键变量维度与含义



| **变量**     | **数学表达**     | **维度**     | **物理/几何含义**                              |
| ------------ | ---------------- | ------------ | ---------------------------------------------- |
| **主语键**   | $k^*$            | $h \times 1$ | 目标主语在 MLP 内部的神经激活模式。            |
| **目标值**   | $v^*$            | $d \times 1$ | 能触发后续层输出正确宾语的最优向量。           |
| **记忆统计** | $C$              | $h \times h$ | 预训练期间键向量的非中心化协方差矩阵。         |
| **投影键**   | $z = C^{-1} k^*$ | $h \times 1$ | 经过去相关处理后的键，使得编辑方向干扰最小化。 |
| **更新系数** | $\lambda$        | $d \times 1$ | 调整权重所需的强度向量，正比于输出误差。       |

------



## 7. 算法实现细节与计算复杂性



在实际操作中，计算 ROME 更新量不仅涉及理论公式，还涉及具体的工程实现。



### 7.1 协方差矩阵 $C$ 的估计



理论上 $C$ 需要遍历整个预训练数据集。实际上，这不仅计算量大而且不必要。ROME 论文指出，使用约 100,000 个随机抽取的 Wiki 文本样本即可获得足够好的 $C$ 估计 3。



$$C \approx \frac{1}{N} \sum_{i=1}^{N} k(x_i) k(x_i)^T$$



由于 $C$ 仅取决于预训练模型和通用文本分布，而与具体的编辑任务无关，因此它可以预先计算并缓存（Pre-cached）。这大大加快了后续单次编辑的速度。



### 7.2 矩阵求逆与数值稳定性



直接计算 $C^{-1}$ 可能面临数值不稳定性（如果 $C$ 接近奇异）。通常采用以下策略：

1. **正则化（Regularization）：** 计算 $(C + \alpha I)^{-1}$，其中 $\alpha$ 是一个小常数（岭回归）。这不仅防止除零错误，还能限制权重的过度增长。
2. **低秩更新公式：** 如果 $C$ 已经缓存了逆矩阵，当有新数据加入时，可以使用 Sherman-Morrison 公式进行在线更新，但这在 ROME 的标准用法中不常见，因为我们假设 $C$ 是静态的背景知识。



### 7.3 ROME 与 MEMIT 的对比



ROME 是单次编辑（Rank-One）。如果我们要同时编辑 $E$ 个事实，直接叠加 $E$ 个 ROME 更新是次优的，因为后一个更新可能会干扰前一个。

MEMIT (Mass-Editing Memory in a Transformer) 9 将 ROME 的推导推广到了多约束情况：



$$\text{minimize} \quad \|\hat{W} K_0 - V_0\|_F^2 + \sum_{i=1}^E \|\hat{W} k_i - v_i\|_F^2$$



其闭式解变为：



$$\hat{W} = W_0 + (V_{new} - W_0 K_{new})(C_0 + K_{new}K_{new}^T)^{-1} K_{new}^T$$



当 $E=1$ 时，MEMIT 的公式退化为 ROME 的公式。这进一步验证了 ROME 推导的普适性。

------



## 8. 讨论与结论





### 8.1 为什么是秩一（Rank-One）？



从线性代数的角度看，权重矩阵 $W$ 的秩（Rank）决定了其存储信息的容量。每次 ROME 操作实际上是向 $W$ 添加了一个秩为 1 的修正矩阵。这意味着每次编辑只占用矩阵的一个“自由度”。对于一个维度 $h=10000$的 MLP 层，理论上可以支持数千次 ROME 编辑而不发生显著的“记忆饱和”，前提是这些编辑的键 $k^*$ 之间是线性无关的。



### 8.2 方法局限性



尽管数学推导严谨，ROME 仍面临挑战：

1. **定位准确性依赖：** ROME 的有效性完全依赖于 $l^*$ 层确实是知识存储位置的假设。如果知识是跨层分布式存储的，单层秩一更新可能无法彻底改变输出。
2. **本质漂移的权衡：** $\mathcal{L}_{KL}$ 项虽然在优化 $v^*$ 时引入了，但在最终的权重更新公式 $\Delta W$ 中，并没有显式的项来强制 $KL$ 散度最小化（仅通过 $C^{-1}$ 隐式实现）。这导致在极端情况下，强行满足 $\hat{W} k^* = v^*$ 可能会对局部邻域造成破坏。



### 8.3 总结



ROME 技术的参数更新量推导是一个将**深度学习可解释性**与**经典线性代数优化**完美结合的典范。

1. 它首先通过**因果分析**锁定问题的物理位置（MLP层）。
2. 然后通过**统计平均**提取问题的数学表征（$k^*$）。
3. 接着通过**梯度优化**解码出期望的神经激活（$v^*$）。
4. 最后利用**拉格朗日乘数法**在最小二乘框架下求得最优的参数微调量 $\Delta W$。

这一过程不仅为大模型的知识修正提供了一种高效工具，更为我们理解神经网络内部的“知识表示”提供了深刻的数学视角：知识即是高维空间中的键值映射，而学习（或遗忘）则是对这些映射关系的几何变换。

------

本报告中的所有推导和结论均基于提供的研究片段 1 及相关数学原理。